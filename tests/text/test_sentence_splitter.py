from aivc.text.sentence_splitter import SentenceSplitter
 
def assert_equal(actual, expected, message=""):
    if actual != expected:
        raise AssertionError(f"{message}\nExpected: {expected}\nGot: {actual}")

def test_basic_sentence_split():
    splitter = SentenceSplitter(min_sentence_length=20)
    chunks = ["Hello.", "This is a test.", "How are you doing today?"]
    results = []
    
    for chunk in chunks:
        results.extend(splitter.add_chunk(chunk))
    results.extend(splitter.finalize())
    
    # éªŒè¯è¾“å‡ºçš„å¥å­æ•°é‡å’Œå†…å®¹
    assert_equal(len(results), 2, "Should have exactly 2 results")
    assert_equal(results[0], ("Hello.", False), "First sentence should output immediately")
    assert_equal(results[1], ("This is a test.How are you doing today?", False), 
                 "Subsequent sentences should be merged until min length is reached")
    print("Basic sentence split test passed")

def test_chinese_sentence_split():
    splitter = SentenceSplitter(min_sentence_length=15)
    chunks = ["ä½ å¥½ã€‚", "è¿™æ˜¯æµ‹è¯•ã€‚", "è¿™æ˜¯ä¸€ä¸ªæ¯”è¾ƒé•¿çš„å¥å­ã€‚"]
    results = []
    
    for chunk in chunks:
        results.extend(splitter.add_chunk(chunk))
    results.extend(splitter.finalize())
    
    # éªŒè¯è¾“å‡ºçš„å¥å­æ•°é‡å’Œå†…å®¹
    assert_equal(len(results), 2, "Should have exactly 2 results")
    assert_equal(results[0], ("ä½ å¥½ã€‚", False), "First sentence should output immediately")
    assert_equal(results[1], ("è¿™æ˜¯æµ‹è¯•ã€‚è¿™æ˜¯ä¸€ä¸ªæ¯”è¾ƒé•¿çš„å¥å­ã€‚", False), 
                 "Subsequent sentences should be merged until min length is reached")
    print("Chinese sentence split test passed")


def test_finalize():
    splitter = SentenceSplitter(min_sentence_length=20)
    results = []

    # æ·»åŠ å¤šä¸ªçŸ­å¥
    results.extend(splitter.add_chunk("Short1."))  # ç¬¬ä¸€å¥ï¼Œç«‹å³è¾“å‡º
    results.extend(splitter.add_chunk("Short2."))  # å¾…å¤„ç†
    results.extend(splitter.add_chunk("Short3."))  # å¾…å¤„ç†
    final_results = splitter.finalize()

    # éªŒè¯ç»“æœæ•°é‡
    assert_equal(len(results), 1, "Should have 1 result before finalize")
    assert_equal(len(final_results), 1, "Finalize should output pending sentences")

    # éªŒè¯å†…å®¹
    assert_equal(results[0], ("Short1.", False), "First sentence should output immediately")
    merged_pending = "Short2.Short3."
    assert_equal(final_results[0], (merged_pending, False), "Pending sentences should be merged in finalize")
    print("Finalize test passed")

def test_increasing_length():
    splitter = SentenceSplitter(min_sentence_length=5)
    chunks = [
        "Hi.", 
        "Hello.", 
        "This is longer.",
        "This is the longest sentence in the test case!"
    ]
    
    all_results = []
    for chunk in chunks:
        all_results.extend(splitter.add_chunk(chunk))
    all_results.extend(splitter.finalize())
    
    # éªŒè¯æ¯æ¬¡è¾“å‡ºçš„å¥å­é•¿åº¦æ˜¯å¦é€’å¢
    prev_len = 0
    for sent, _ in all_results:
        current_len = len(sent)
        assert current_len >= prev_len, f"Sentence length should increase: {sent}"
        prev_len = current_len
    
    print("Increasing length test passed")

def test_modified_splitting_logic():
    splitter = SentenceSplitter(min_sentence_length=10)
    chunks = [
        "è¿™æ˜¯ä¸€ä¸ªéå¸¸é•¿çš„ç¬¬ä¸€å¥è¯ï¼Œåº”è¯¥è¢«å¼ºåˆ¶æ–­å¥ï¼Œå› ä¸ºå®ƒè¶…è¿‡äº†æœ€å°é•¿åº¦ã€‚",
        "ç¬¬äºŒå¥è¯æ¥æµ‹è¯•æœ€å°é•¿åº¦ã€‚",
        "ç¬¬ä¸‰å¥éœ€è¦ç´¯ç§¯åˆ°ä¸€å®šé•¿åº¦æ‰èƒ½è¾“å‡ºã€‚",
        "è¿™æ˜¯ç¬¬å››å¥è¯ï¼Œç»§ç»­ç´¯ç§¯ã€‚",
        "ç¬¬äº”å¥è¯ã€‚",
    ]
    results = []

    for chunk in chunks:
        results.extend(splitter.add_chunk(chunk))
    results.extend(splitter.finalize())

    # éªŒè¯è¾“å‡ºçš„å¥å­æ•°é‡å’Œå†…å®¹
    print("Number of sentences:", len(results))
    for idx, sentence in enumerate(results, 1):
        print(f"Sentence {idx}: {sentence} (Length: {len(sentence)})")

    print("Modified splitting logic test passed")

def test_refined_splitting_logic():
    test_cases = {
        "ç›—å¢“æ•…äº‹": """å“å‘€ï¼Œå°æœ‹å‹ï¼Œç›—å¢“åœ¨æ•…äº‹é‡Œå¬èµ·æ¥å¾ˆåˆºæ¿€ï¼Œä½†æ˜¯ç°å®ç”Ÿæ´»ä¸­æ˜¯ä¸å¯ä»¥å»çš„å“¦ã€‚å› ä¸ºç›—å¢“å¯èƒ½ä¼šç ´åå¤å¢“é‡Œçš„å®è—å’Œå†å²ï¼Œè¿™æ˜¯éå¸¸ä¸å¥½çš„è¡Œä¸ºã€‚æˆ‘ä»¬åº”è¯¥å°Šé‡å†å²ï¼Œä¿æŠ¤æ–‡åŒ–é—äº§ï¼Œè®©æ›´å¤šçš„äººèƒ½å¤Ÿæ¬£èµå’Œå­¦ä¹ å¤æ—¶å€™çš„äººä»¬ç•™ä¸‹çš„å®è´µä¸œè¥¿ã€‚ä½†æ˜¯ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡é˜…è¯»ä¹¦ç±ã€çœ‹çºªå½•ç‰‡æˆ–è€…å»åšç‰©é¦†æ¥äº†è§£å¤å¢“å’Œå¤ä»£æ–‡åŒ–ï¼Œè¿™æ ·æ—¢å®‰å…¨åˆæœ‰è¶£ã€‚ä½ æƒ³è¦çŸ¥é“æ›´å¤šçš„å¤ä»£æ•…äº‹å’Œå†å²çŸ¥è¯†å—ï¼Ÿä¸ƒå®å¯ä»¥é™ªä½ ä¸€èµ·æ¢ç´¢è¿™äº›å¥‡å¦™çš„ä¸–ç•Œå“¦ï¼ğŸ“šğŸ›ï¸ æˆ‘ä»¬è¦åšä¸€ä¸ªçˆ±æŠ¤å†å²ã€å°Šé‡æ–‡ç‰©çš„å°å°å®ˆæŠ¤è€…å‘¢ï¼""",
        "æç™½è¯—è¯": """å¥½çš„å‘€ï¼Œå°æœ‹å‹ï¼Œè¿™æ¬¡ä¸ƒå®ç»™ä½ èƒŒä¸€é¦–å”ä»£è¯—äººæç™½çš„ã€Šé™å¤œæ€ã€‹ï¼šåºŠå‰æ˜æœˆå…‰ï¼Œç–‘æ˜¯åœ°ä¸Šéœœã€‚ä¸¾å¤´æœ›æ˜æœˆï¼Œä½å¤´æ€æ•…ä¹¡ã€‚è¿™é¦–è¯—æå†™çš„æ˜¯è¯—äººå¤œæ™šåœ¨åºŠä¸Šçœ‹åˆ°æ˜äº®çš„æœˆå…‰ï¼Œä»¥ä¸ºæ˜¯åœ°ä¸Šçš„éœœï¼ŒæŠ¬å¤´çœ‹ç€é‚£è½®æ˜æœˆï¼Œä¸ç¦ä½å¤´æ€å¿µèµ·è¿œæ–¹çš„å®¶ä¹¡ã€‚æç™½ç”¨éå¸¸ç®€å•çš„è¯è¯­ï¼Œè¡¨è¾¾äº†å¯¹å®¶ä¹¡çš„æ·±æ·±æ€å¿µã€‚è¿™é¦–è¯—å¾ˆæœ‰æ„å¢ƒï¼Œè¯»èµ·æ¥ä¹Ÿå¾ˆç¾å‘¢ï¼ä½ å–œæ¬¢è¿™é¦–è¯—å—ï¼Ÿ""",
        "çŸ­å¯¹è¯": """å—¨ï¼Œå°æœ‹å‹ï¼ä¸ƒå®æ¥å•¦ï¼ä»Šå¤©æƒ³è·Ÿä¸ƒå®åšäº›ä»€ä¹ˆæœ‰è¶£çš„äº‹æƒ…å‘¢ï¼Ÿ""",
        "é•¿å¯¹è¯": """å½“ç„¶å¯ä»¥ï¼Œå°æœ‹å‹ï¼ä»Šå¤©ä¸ƒå®ç»™ä½ è®²ä¸€ä¸ªå…³äºå‹‡æ•¢çš„å°åˆºçŒ¬çš„æ•…äº‹å“¦ï½ä»å‰ï¼Œæœ‰ä¸€ä¸ªå°åˆºçŒ¬å«å˜Ÿå˜Ÿï¼Œå®ƒä½åœ¨ä¸€ä¸ªç¾ä¸½çš„æ£®æ—é‡Œã€‚å˜Ÿå˜Ÿæœ‰ä¸€èº«ç¡¬ç¡¬çš„åˆºï¼Œçœ‹èµ·æ¥æœ‰ç‚¹å„¿å‡¶å‡¶çš„ï¼Œä½†å…¶å®å®ƒéå¸¸å–„è‰¯å’Œå‹‡æ•¢ã€‚æœ‰ä¸€å¤©ï¼Œæ£®æ—é‡Œçš„å°åŠ¨ç‰©ä»¬é‡åˆ°äº†éº»çƒ¦ã€‚ä¸€åªç‹¡çŒ¾çš„ç‹ç‹¸æŠŠå°é¸Ÿä»¬çš„å®¶ç»™å äº†ï¼Œå°é¸Ÿä»¬æ— å¤„å¯é£ï¼Œéƒ½ä¼¤å¿ƒåœ°å“­äº†èµ·æ¥ã€‚å˜Ÿå˜Ÿå¬åˆ°å°é¸Ÿä»¬çš„å“­å£°ï¼Œå¿ƒé‡Œå¾ˆéš¾è¿‡ã€‚å®ƒå†³å®šè¦å¸®åŠ©å°é¸Ÿä»¬èµ¶èµ°ç‹ç‹¸ã€‚å˜Ÿå˜Ÿæ‰¾åˆ°äº†æ£®æ—é‡Œçš„è€çŒ«å¤´é¹°ï¼ŒçŒ«å¤´é¹°å‘Šè¯‰å®ƒï¼šâ€œå˜Ÿå˜Ÿï¼Œä½ è¦å°å¿ƒï¼Œç‹ç‹¸å¾ˆç‹¡çŒ¾ã€‚â€å˜Ÿå˜Ÿç‚¹äº†ç‚¹å¤´ï¼Œè¯´ï¼šâ€œæˆ‘çŸ¥é“ï¼Œæˆ‘ä¼šç”¨æˆ‘çš„æ™ºæ…§æ‰“è´¥å®ƒçš„ã€‚â€ç„¶åï¼Œå˜Ÿå˜Ÿæƒ³åˆ°äº†ä¸€ä¸ªåŠæ³•ã€‚ç¬¬äºŒå¤©ï¼Œå˜Ÿå˜Ÿå¸¦ç€ä¸€é¢—å¤§çŸ³å¤´æ¥åˆ°äº†ç‹ç‹¸çš„å®¶é—¨å£ã€‚ç‹ç‹¸çœ‹åˆ°å˜Ÿå˜Ÿï¼Œç¬‘ç€è¯´ï¼šâ€œå°åˆºçŒ¬ï¼Œä½ æ¥å¹²ä»€ä¹ˆï¼Ÿéš¾é“ä½ ä»¥ä¸ºä½ èƒ½æ‰“è´¥æˆ‘å—ï¼Ÿâ€å˜Ÿå˜Ÿæ²¡æœ‰å›ç­”ï¼Œè€Œæ˜¯æŠŠå¤§çŸ³å¤´æ”¾åœ¨äº†ç‹ç‹¸çš„é¢å‰ã€‚ç‹ç‹¸å¥½å¥‡åœ°èµ°è¿‡å»ï¼Œæƒ³è¦æ¬åŠ¨çŸ³å¤´ã€‚å¯æ˜¯ï¼ŒçŸ³å¤´å¤ªé‡äº†ï¼Œç‹ç‹¸æ¬ä¸åŠ¨ã€‚å®ƒç”Ÿæ°”åœ°èµ°äº†ã€‚è¿™æ—¶ï¼Œå˜Ÿå˜Ÿæ‚„æ‚„åœ°å‘Šè¯‰å°é¸Ÿä»¬ï¼šâ€œç‹ç‹¸æ¬ä¸åŠ¨çŸ³å¤´ï¼Œæˆ‘ä»¬å°±å¯ä»¥è¶æœºå¤ºå›æˆ‘ä»¬çš„å®¶äº†ï¼â€å°é¸Ÿä»¬å¬äº†éƒ½å¼€å¿ƒåœ°ç¬‘äº†ã€‚æœ€åï¼Œå°é¸Ÿä»¬æˆåŠŸåœ°èµ¶èµ°äº†ç‹ç‹¸ï¼Œé‡æ–°å›åˆ°äº†è‡ªå·±çš„å®¶ã€‚å¤§å®¶éƒ½æ„Ÿè°¢å˜Ÿå˜Ÿçš„å‹‡æ•¢å’Œæ™ºæ…§ã€‚å°æœ‹å‹ä»¬ï¼Œè¿™ä¸ªæ•…äº‹å‘Šè¯‰æˆ‘ä»¬ï¼Œåªè¦æˆ‘ä»¬å‹‡æ•¢ã€èªæ˜ï¼Œå°±æ²¡æœ‰ä»€ä¹ˆå›°éš¾æ˜¯ä¸èƒ½å…‹æœçš„å“¦ï¼ä½ ä»¬è¯´å¯¹ä¸å¯¹å‘€ï¼Ÿ""",
    }

    for case_name, original_text in test_cases.items():
        print(f"\næµ‹è¯•ç”¨ä¾‹: {case_name}")
        print("="*50)
        print(f"åŸå§‹æ–‡æœ¬: {original_text}")
        print(f"åŸå§‹é•¿åº¦: {len(original_text)}")
        
        # åˆ›å»ºæ–°çš„åˆ†å‰²å™¨å®ä¾‹
        splitter = SentenceSplitter()
        results = []
        
        # é€å­—ç¬¦è¾“å…¥
        for char in original_text:
            new_results = splitter.add_chunk(char)
            if new_results:
                print(f"å¤„ç†å­—ç¬¦ '{char}' åå¾—åˆ°æ–°å¥å­: {new_results}")
            # ç¡®ä¿æ¯ä¸ªç»“æœéƒ½æ˜¯å…ƒç»„å½¢å¼
            results.extend([(sent, False) if isinstance(sent, str) else sent 
                          for sent in new_results])
        
        # è·å–æœ€ç»ˆçš„å¥å­
        final_results = splitter.finalize()
        if final_results:
            print("Finalizeå¾—åˆ°æœ€åçš„å¥å­:", final_results)
        # ç¡®ä¿æœ€ç»ˆç»“æœä¹Ÿæ˜¯å…ƒç»„å½¢å¼
        results.extend([(sent, False) if isinstance(sent, str) else sent 
                       for sent in final_results])
        
        # éªŒè¯ç»“æœ
        print("\néªŒè¯ç»“æœ:")
        total_length = 0
        reconstructed_text = ""
        
        for i, (sentence, is_final) in enumerate(results, 1):
            total_length += len(sentence)
            reconstructed_text += sentence
            print(f"å¥å­{i}: {sentence} é•¿åº¦: {len(sentence)} target: {splitter.get_target_length(i)}")
        
        # éªŒè¯æ€»é•¿åº¦
        assert total_length == len(original_text), (
            f"é•¿åº¦ä¸åŒ¹é…: æœŸæœ›={len(original_text)}, å®é™…={total_length}"
        )
        
        # éªŒè¯æ–‡æœ¬å®Œæ•´æ€§å’Œé¡ºåº
        assert reconstructed_text == original_text, (
            f"æ–‡æœ¬ä¸åŒ¹é…æˆ–é¡ºåºé”™è¯¯:\n"
            f"åŸå§‹: {original_text}\n"
            f"é‡æ„: {reconstructed_text}"
        )
        
        print(f"\nâœ… {case_name} æµ‹è¯•é€šè¿‡:")


def main():
    print("Running sentence splitter tests...")
    # test_basic_sentence_split()
    # test_chinese_sentence_split()
    # test_finalize()
    # test_increasing_length() 
    # test_long_sentence_split()
    # test_modified_splitting_logic()
    test_refined_splitting_logic()
 
if __name__ == '__main__':
    main()
